{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Submission By : **Krishn Parasar** \n",
        "\n",
        "ID : **2020A7PS2093H**    \n",
        " \n",
        "        "
      ],
      "metadata": {
        "id": "FMdVW_QFGiU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Done as Team project with 3 other group members :\n",
        "1. Shreyash Bhardwaj 2020A7PS2066H\n",
        "2. Nikhil Raj 2020A7PS0093H\n",
        "3. Hirakjyoti Nath 2020A7PS2078H"
      ],
      "metadata": {
        "id": "C-yQdJ4sG3Tr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "mqFe_1SV2RXB",
        "outputId": "e928bb1d-4ac5-46ce-f6a2-8c6502fc0ffa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                   0.07871  ...          17.33           184.60      2019.0   \n",
              "1                   0.05667  ...          23.41           158.80      1956.0   \n",
              "2                   0.05999  ...          25.53           152.50      1709.0   \n",
              "3                   0.09744  ...          26.50            98.87       567.7   \n",
              "4                   0.05883  ...          16.67           152.20      1575.0   \n",
              "..                      ...  ...            ...              ...         ...   \n",
              "564                 0.05623  ...          26.40           166.10      2027.0   \n",
              "565                 0.05533  ...          38.25           155.00      1731.0   \n",
              "566                 0.05648  ...          34.12           126.70      1124.0   \n",
              "567                 0.07016  ...          39.42           184.60      1821.0   \n",
              "568                 0.05884  ...          30.37            59.16       268.6   \n",
              "\n",
              "     worst smoothness  worst compactness  worst concavity  \\\n",
              "0             0.16220            0.66560           0.7119   \n",
              "1             0.12380            0.18660           0.2416   \n",
              "2             0.14440            0.42450           0.4504   \n",
              "3             0.20980            0.86630           0.6869   \n",
              "4             0.13740            0.20500           0.4000   \n",
              "..                ...                ...              ...   \n",
              "564           0.14100            0.21130           0.4107   \n",
              "565           0.11660            0.19220           0.3215   \n",
              "566           0.11390            0.30940           0.3403   \n",
              "567           0.16500            0.86810           0.9387   \n",
              "568           0.08996            0.06444           0.0000   \n",
              "\n",
              "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
              "0                  0.2654          0.4601                  0.11890     0.0  \n",
              "1                  0.1860          0.2750                  0.08902     0.0  \n",
              "2                  0.2430          0.3613                  0.08758     0.0  \n",
              "3                  0.2575          0.6638                  0.17300     0.0  \n",
              "4                  0.1625          0.2364                  0.07678     0.0  \n",
              "..                    ...             ...                      ...     ...  \n",
              "564                0.2216          0.2060                  0.07115     0.0  \n",
              "565                0.1628          0.2572                  0.06637     0.0  \n",
              "566                0.1418          0.2218                  0.07820     0.0  \n",
              "567                0.2650          0.4087                  0.12400     0.0  \n",
              "568                0.0000          0.2871                  0.07039     1.0  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7695ef56-c573-4bc9-a30e-2c311cd6b94f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7695ef56-c573-4bc9-a30e-2c311cd6b94f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7695ef56-c573-4bc9-a30e-2c311cd6b94f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7695ef56-c573-4bc9-a30e-2c311cd6b94f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/AIP-BITS/BITS-DATA/main/cancer.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings"
      ],
      "metadata": {
        "id": "jptXkaj-70Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "l5SwaDb7npQi",
        "outputId": "1677a60e-99b6-47fd-d36f-d4e9bae5a38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       mean radius  mean texture  mean perimeter    mean area  \\\n",
              "count   569.000000    569.000000      569.000000   569.000000   \n",
              "mean     14.127292     19.289649       91.969033   654.889104   \n",
              "std       3.524049      4.301036       24.298981   351.914129   \n",
              "min       6.981000      9.710000       43.790000   143.500000   \n",
              "25%      11.700000     16.170000       75.170000   420.300000   \n",
              "50%      13.370000     18.840000       86.240000   551.100000   \n",
              "75%      15.780000     21.800000      104.100000   782.700000   \n",
              "max      28.110000     39.280000      188.500000  2501.000000   \n",
              "\n",
              "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
              "count       569.000000        569.000000      569.000000           569.000000   \n",
              "mean          0.096360          0.104341        0.088799             0.048919   \n",
              "std           0.014064          0.052813        0.079720             0.038803   \n",
              "min           0.052630          0.019380        0.000000             0.000000   \n",
              "25%           0.086370          0.064920        0.029560             0.020310   \n",
              "50%           0.095870          0.092630        0.061540             0.033500   \n",
              "75%           0.105300          0.130400        0.130700             0.074000   \n",
              "max           0.163400          0.345400        0.426800             0.201200   \n",
              "\n",
              "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
              "count     569.000000              569.000000  ...     569.000000   \n",
              "mean        0.181162                0.062798  ...      25.677223   \n",
              "std         0.027414                0.007060  ...       6.146258   \n",
              "min         0.106000                0.049960  ...      12.020000   \n",
              "25%         0.161900                0.057700  ...      21.080000   \n",
              "50%         0.179200                0.061540  ...      25.410000   \n",
              "75%         0.195700                0.066120  ...      29.720000   \n",
              "max         0.304000                0.097440  ...      49.540000   \n",
              "\n",
              "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
              "count       569.000000   569.000000        569.000000         569.000000   \n",
              "mean        107.261213   880.583128          0.132369           0.254265   \n",
              "std          33.602542   569.356993          0.022832           0.157336   \n",
              "min          50.410000   185.200000          0.071170           0.027290   \n",
              "25%          84.110000   515.300000          0.116600           0.147200   \n",
              "50%          97.660000   686.500000          0.131300           0.211900   \n",
              "75%         125.400000  1084.000000          0.146000           0.339100   \n",
              "max         251.200000  4254.000000          0.222600           1.058000   \n",
              "\n",
              "       worst concavity  worst concave points  worst symmetry  \\\n",
              "count       569.000000            569.000000      569.000000   \n",
              "mean          0.272188              0.114606        0.290076   \n",
              "std           0.208624              0.065732        0.061867   \n",
              "min           0.000000              0.000000        0.156500   \n",
              "25%           0.114500              0.064930        0.250400   \n",
              "50%           0.226700              0.099930        0.282200   \n",
              "75%           0.382900              0.161400        0.317900   \n",
              "max           1.252000              0.291000        0.663800   \n",
              "\n",
              "       worst fractal dimension      target  \n",
              "count               569.000000  569.000000  \n",
              "mean                  0.083946    0.627417  \n",
              "std                   0.018061    0.483918  \n",
              "min                   0.055040    0.000000  \n",
              "25%                   0.071460    0.000000  \n",
              "50%                   0.080040    1.000000  \n",
              "75%                   0.092080    1.000000  \n",
              "max                   0.207500    1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-501e811a-1ed7-4830-a4ac-84b50d210945\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "      <td>569.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>19.289649</td>\n",
              "      <td>91.969033</td>\n",
              "      <td>654.889104</td>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.181162</td>\n",
              "      <td>0.062798</td>\n",
              "      <td>...</td>\n",
              "      <td>25.677223</td>\n",
              "      <td>107.261213</td>\n",
              "      <td>880.583128</td>\n",
              "      <td>0.132369</td>\n",
              "      <td>0.254265</td>\n",
              "      <td>0.272188</td>\n",
              "      <td>0.114606</td>\n",
              "      <td>0.290076</td>\n",
              "      <td>0.083946</td>\n",
              "      <td>0.627417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.524049</td>\n",
              "      <td>4.301036</td>\n",
              "      <td>24.298981</td>\n",
              "      <td>351.914129</td>\n",
              "      <td>0.014064</td>\n",
              "      <td>0.052813</td>\n",
              "      <td>0.079720</td>\n",
              "      <td>0.038803</td>\n",
              "      <td>0.027414</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>...</td>\n",
              "      <td>6.146258</td>\n",
              "      <td>33.602542</td>\n",
              "      <td>569.356993</td>\n",
              "      <td>0.022832</td>\n",
              "      <td>0.157336</td>\n",
              "      <td>0.208624</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.061867</td>\n",
              "      <td>0.018061</td>\n",
              "      <td>0.483918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>6.981000</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>43.790000</td>\n",
              "      <td>143.500000</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106000</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>...</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>50.410000</td>\n",
              "      <td>185.200000</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>11.700000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>75.170000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>0.086370</td>\n",
              "      <td>0.064920</td>\n",
              "      <td>0.029560</td>\n",
              "      <td>0.020310</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.057700</td>\n",
              "      <td>...</td>\n",
              "      <td>21.080000</td>\n",
              "      <td>84.110000</td>\n",
              "      <td>515.300000</td>\n",
              "      <td>0.116600</td>\n",
              "      <td>0.147200</td>\n",
              "      <td>0.114500</td>\n",
              "      <td>0.064930</td>\n",
              "      <td>0.250400</td>\n",
              "      <td>0.071460</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.370000</td>\n",
              "      <td>18.840000</td>\n",
              "      <td>86.240000</td>\n",
              "      <td>551.100000</td>\n",
              "      <td>0.095870</td>\n",
              "      <td>0.092630</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.033500</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>...</td>\n",
              "      <td>25.410000</td>\n",
              "      <td>97.660000</td>\n",
              "      <td>686.500000</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.226700</td>\n",
              "      <td>0.099930</td>\n",
              "      <td>0.282200</td>\n",
              "      <td>0.080040</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>15.780000</td>\n",
              "      <td>21.800000</td>\n",
              "      <td>104.100000</td>\n",
              "      <td>782.700000</td>\n",
              "      <td>0.105300</td>\n",
              "      <td>0.130400</td>\n",
              "      <td>0.130700</td>\n",
              "      <td>0.074000</td>\n",
              "      <td>0.195700</td>\n",
              "      <td>0.066120</td>\n",
              "      <td>...</td>\n",
              "      <td>29.720000</td>\n",
              "      <td>125.400000</td>\n",
              "      <td>1084.000000</td>\n",
              "      <td>0.146000</td>\n",
              "      <td>0.339100</td>\n",
              "      <td>0.382900</td>\n",
              "      <td>0.161400</td>\n",
              "      <td>0.317900</td>\n",
              "      <td>0.092080</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.110000</td>\n",
              "      <td>39.280000</td>\n",
              "      <td>188.500000</td>\n",
              "      <td>2501.000000</td>\n",
              "      <td>0.163400</td>\n",
              "      <td>0.345400</td>\n",
              "      <td>0.426800</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.304000</td>\n",
              "      <td>0.097440</td>\n",
              "      <td>...</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>251.200000</td>\n",
              "      <td>4254.000000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>1.058000</td>\n",
              "      <td>1.252000</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.663800</td>\n",
              "      <td>0.207500</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-501e811a-1ed7-4830-a4ac-84b50d210945')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-501e811a-1ed7-4830-a4ac-84b50d210945 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-501e811a-1ed7-4830-a4ac-84b50d210945');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibXRjj4gqplM",
        "outputId": "d94f2662-b4e6-4f90-a5e0-6ced8c6f44b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autoviz\n",
        "from autoviz.AutoViz_Class import AutoViz_Class\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/AIP-BITS/BITS-DATA/main/cancer.csv\") \n",
        "autoviz = AutoViz_Class().AutoViz(\"https://raw.githubusercontent.com/AIP-BITS/BITS-DATA/main/cancer.csv\")"
      ],
      "metadata": {
        "id": "Nh890E9u59jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "X = df.iloc[:,0:29]\n",
        "y = df.iloc[:,-1]   \n",
        "BestFeatures = SelectKBest(score_func=chi2, k=20)\n",
        "fit = BestFeatures.fit(X,y)\n",
        "df_scores = pd.DataFrame(fit.scores_)\n",
        "df_columns = pd.DataFrame(X.columns)\n",
        "f_Scores = pd.concat([df_columns,df_scores],axis=1)         \n",
        "f_Scores.columns = ['Specs','Score']  \n",
        "cols = BestFeatures.get_support(indices=True)\n",
        "df_1 =X.iloc[:,cols]"
      ],
      "metadata": {
        "id": "wsgt1FtCuAfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "FtMMWPOzzQdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-2 **Decision tree Classifier**"
      ],
      "metadata": {
        "id": "bv3QGgrEbxr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import metrics\n",
        "classifier = DecisionTreeClassifier()\n",
        "params = {'max_depth': [2, 3, 5, 10, 20],'min_samples_leaf': [5, 10, 20, 50, 100],'criterion': [\"gini\", \"entropy\"]}\n",
        "grid= GridSearchCV(estimator=classifier, param_grid=params, cv=4, verbose=1, scoring = \"accuracy\")\n",
        "classifier_4 = grid.fit(X_train,y_train)\n",
        "st=time.time()\n",
        "y_pred = classifier_4.predict(X_test)\n",
        "tst=time.time()-st\n",
        "accuracy_tree=metrics.accuracy_score(y_test, y_pred)\n",
        "bsthp=classifier_4.best_params_\n",
        "print(\"Accuracy \"+str(accuracy_tree))\n",
        "print(\"Best Hyperparameters \"+str(bsthp))\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision_score = precision_score(y_test, y_pred)\n",
        "recall_score = recall_score(y_test, y_pred)\n",
        "print(\"Precision Score \"+str(precision_score))\n",
        "print(\"Recall Score \"+str(recall_score))\n",
        "f1_score=f1_score(y_test,y_pred)\n",
        "print(\"F1 score \"+str(f1_score))\n",
        "print(\"Testing time \"+str(tst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUq7caRXFHLB",
        "outputId": "fbfcef71-3545-4455-8fbd-e8c552a18a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
            "Accuracy 0.9692982456140351\n",
            "Best Hyperparameters {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 10}\n",
            "Precision Score 0.9668874172185431\n",
            "Recall Score 0.9864864864864865\n",
            "F1 score 0.9765886287625419\n",
            "Testing time 0.0014758110046386719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-3 **NaiveBayes**"
      ],
      "metadata": {
        "id": "aTTOcgc1YC7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn import metrics\n",
        "classifier = BernoulliNB()\n",
        "cf=classifier.fit(X_train, y_train)\n",
        "st=time.time()\n",
        "y_pred=cf.predict(X_test)\n",
        "tst=time.time()-st\n",
        "from sklearn.metrics import accuracy_score\n",
        "bstsc=metrics.accuracy_score(y_test, y_pred)\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision_score = precision_score(y_test, y_pred)\n",
        "recall_score = recall_score(y_test, y_pred)\n",
        "print(\"Precision Score \"+str(precision_score))\n",
        "print(\"Recall Score \"+str(recall_score))\n",
        "print(\"Accuracy \"+str(bstsc))\n",
        "f1_score=f1_score(y_test,y_pred)\n",
        "print(\"F1 score \"+str(f1_score))\n",
        "print(\"Testing time \"+str(tst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FyFzba_aNIr",
        "outputId": "3a960323-88fc-48a9-ea12-8075bbb27816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score 0.6491228070175439\n",
            "Recall Score 1.0\n",
            "Accuracy 0.6491228070175439\n",
            "F1 score 0.7872340425531915\n",
            "Testing time 0.003277301788330078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "classifier = GaussianNB()\n",
        "cf=classifier.fit(X_train, y_train)\n",
        "st=time.time()\n",
        "y_pred=cf.predict(X_test)\n",
        "tst=time.time()-st\n",
        "from sklearn.metrics import accuracy_score\n",
        "bstsc=metrics.accuracy_score(y_test, y_pred)\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision_score = precision_score(y_test, y_pred)\n",
        "recall_score = recall_score(y_test, y_pred)\n",
        "print(\"Precision Score \"+str(precision_score))\n",
        "print(\"Recall Score \"+str(recall_score))\n",
        "print(\"Accuracy \"+str(bstsc))\n",
        "f1_score=f1_score(y_test,y_pred)\n",
        "print(\"F1 score \"+str(f1_score))\n",
        "print(\"Testing time \"+str(tst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXH0irm5aMhe",
        "outputId": "65ea8409-a1de-431e-834f-a6072b3d495f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score 0.9536423841059603\n",
            "Recall Score 0.972972972972973\n",
            "Accuracy 0.9517543859649122\n",
            "F1 score 0.9632107023411371\n",
            "Testing time 0.001828908920288086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "classifier = GaussianNB()\n",
        "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
        "grid = GridSearchCV(estimator=classifier, param_grid=params_NB, cv=5,verbose=1, scoring='accuracy') \n",
        "classifier_1=grid.fit(X_train,y_train)\n",
        "bsthp=classifier_1.best_params_\n",
        "st=time.time()\n",
        "y_pred = grid.predict(X_test)\n",
        "tst=time.time()-st\n",
        "bstsc=metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Best hyperparameters \"+str(bsthp))\n",
        "print(\"Accuracy \"+str(bstsc))\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision_score = precision_score(y_test, y_pred)\n",
        "recall_score = recall_score(y_test, y_pred)\n",
        "print(\"Precision Score \"+str(precision_score))\n",
        "print(\"Recall Score \"+str(recall_score))\n",
        "f1_score=f1_score(y_test,y_pred)\n",
        "print(\"F1 score \"+str(f1_score))\n",
        "print(\"Testing time \"+str(tst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz2LvUml6-zH",
        "outputId": "78013edc-4855-46ae-f43d-2c3f27444d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Best hyperparameters {'var_smoothing': 1.519911082952933e-09}\n",
            "Accuracy 0.9473684210526315\n",
            "Precision Score 0.9473684210526315\n",
            "Recall Score 0.972972972972973\n",
            "F1 score 0.9599999999999999\n",
            "Testing time 0.001486063003540039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "classifier1 = BernoulliNB()\n",
        "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],'fit_prior': [True, False],'binarize': [None, 0.0, 8.5, 10.0]}\n",
        "grid = GridSearchCV(BernoulliNB(), param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
        "classifier_2=grid.fit(X_train,y_train)\n",
        "bsthp=classifier_2.best_params_\n",
        "st=time.time()\n",
        "y_pred = grid.predict(X_test)\n",
        "tst=time.time()-st\n",
        "bstsc=metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Best hyperparameters \"+str(bsthp))\n",
        "print(\"Accuracy \"+str(bstsc))\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision_score = precision_score(y_test, y_pred)\n",
        "recall_score = recall_score(y_test, y_pred)\n",
        "print(\"Precision Score \"+str(precision_score))\n",
        "print(\"Recall Score \"+str(recall_score))\n",
        "f1_score=f1_score(y_test,y_pred)\n",
        "print(\"F1 score \"+str(f1_score))\n",
        "print(\"Testing time \"+str(tst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcI7eQXh_IyS",
        "outputId": "234f45f9-c0db-4c71-d597-9c5d0337ade4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
            "Best hyperparameters {'alpha': 0.01, 'binarize': 8.5, 'fit_prior': True}\n",
            "Accuracy 0.6754385964912281\n",
            "Precision Score 0.6666666666666666\n",
            "Recall Score 1.0\n",
            "F1 score 0.8\n",
            "Testing time 0.001847982406616211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-4 **SVM**"
      ],
      "metadata": {
        "id": "J8a_lV4TX8AG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "import time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001],'kernel': ['rbf']}\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "st=time.time()\n",
        "classifier_3=grid.fit(X_train, y_train)\n",
        "trt=time.time()-st\n",
        "st=time.time()\n",
        "y_predSVM = grid.predict(X_test)\n",
        "tst=time.time()-st\n",
        "bsthp=classifier_3.best_params_\n",
        "bstsc=metrics.accuracy_score(y_test, y_predSVM)\n",
        "print(\"Best hyperparameters \"+str(bsthp))\n",
        "print(\"Accuracy \"+str(bstsc))\n",
        "print(\"Testing time \"+str(tst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HiYPzgcGK9Y",
        "outputId": "a7a4ebe4-6dcb-49e8-f2d7-6a8342c8da13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.855 total time=   0.0s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.897 total time=   0.0s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.882 total time=   0.0s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.882 total time=   0.0s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.928 total time=   0.0s\n",
            "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.0s\n",
            "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.868 total time=   0.0s\n",
            "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.899 total time=   0.0s\n",
            "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.926 total time=   0.0s\n",
            "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
            "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.632 total time=   0.0s\n",
            "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.632 total time=   0.0s\n",
            "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.913 total time=   0.0s\n",
            "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.838 total time=   0.0s\n",
            "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.957 total time=   0.0s\n",
            "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.926 total time=   0.0s\n",
            "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.926 total time=   0.0s\n",
            "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.926 total time=   0.0s\n",
            "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.632 total time=   0.0s\n",
            "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.632 total time=   0.0s\n",
            "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.913 total time=   0.0s\n",
            "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.838 total time=   0.0s\n",
            "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.941 total time=   0.0s\n",
            "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.941 total time=   0.0s\n",
            "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.609 total time=   0.0s\n",
            "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.618 total time=   0.0s\n",
            "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.632 total time=   0.0s\n",
            "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.632 total time=   0.0s\n",
            "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.603 total time=   0.0s\n",
            "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.913 total time=   0.0s\n",
            "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.897 total time=   0.0s\n",
            "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.838 total time=   0.0s\n",
            "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.868 total time=   0.0s\n",
            "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.912 total time=   0.0s\n",
            "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.926 total time=   0.0s\n",
            "Best hyperparameters {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "Accuracy 0.9429824561403509\n",
            "Testing time 0.004064798355102539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision_score = precision_score(y_test, y_pred)\n",
        "recall_score = recall_score(y_test, y_pred)\n",
        "print(\"Precision Score \"+str(precision_score))\n",
        "print(\"Recall Score \"+str(recall_score))\n",
        "print(\"Accuracy Score \"+str(bstsc))\n",
        "print(\"Training time \"+str(trt))\n",
        "print(\"Testing time \"+str(tst))\n",
        "f1_score=f1_score(y_test,y_pred)\n",
        "print(\"F1 score \"+str(f1_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuNXf_l5Ec2q",
        "outputId": "06de4c39-71c0-4815-be7e-2d6eea4c3fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision Score 0.6666666666666666\n",
            "Recall Score 1.0\n",
            "Accuracy Score 0.9429824561403509\n",
            "Training time 1.6708295345306396\n",
            "Testing time 0.004064798355102539\n",
            "F1 score 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzcz2fqP3lYr",
        "outputId": "3399cbc1-3be1-4f43-8898-e9ba6cd28bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204    1.0\n",
              "70     0.0\n",
              "131    0.0\n",
              "431    1.0\n",
              "540    1.0\n",
              "      ... \n",
              "17     0.0\n",
              "268    1.0\n",
              "66     1.0\n",
              "272    0.0\n",
              "494    1.0\n",
              "Name: target, Length: 228, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observations** :\n",
        "We observed that recall value of the Decision Tree Classifier was the best and it was the fastest among other classifiers with reasonable F1 score and precision value."
      ],
      "metadata": {
        "id": "wgJTUZAfGCOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn import metrics\n",
        "classifier = DecisionTreeClassifier(criterion='entropy', max_depth= 10, min_samples_leaf= 10)\n",
        "params = {'max_depth': [2, 3, 5, 10, 20],'min_samples_leaf': [5, 10, 20, 50, 100],'criterion': [\"gini\", \"entropy\"]}\n",
        "grid= GridSearchCV(estimator=classifier, param_grid=params, cv=4, verbose=1, scoring = \"accuracy\")\n",
        "classifier_4 = grid.fit(X_train,y_train)\n",
        "st=time.time()\n",
        "y_pred = classifier_4.predict(X_test)\n",
        "tst=time.time()-st\n",
        "accuracy_tree=metrics.accuracy_score(y_test, y_pred)\n",
        "bsthp=classifier_4.best_params_\n",
        "print(\"Accuracy \"+str(accuracy_tree))\n",
        "print(\"Best Hyperparameters \"+str(bsthp))\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "precision_score = precision_score(y_test, y_pred)\n",
        "recall_score = recall_score(y_test, y_pred)\n",
        "print(\"Precision Score \"+str(precision_score))\n",
        "print(\"Recall Score \"+str(recall_score))\n",
        "f1_score=f1_score(y_test,y_pred)\n",
        "print(\"F1 score \"+str(f1_score))\n",
        "print(\"Testing time \"+str(tst))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLovqi6QAFxc",
        "outputId": "0935810d-c70f-44d3-cfce-a1264fe823b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
            "Accuracy 0.9692982456140351\n",
            "Best Hyperparameters {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10}\n",
            "Precision Score 0.9668874172185431\n",
            "Recall Score 0.9864864864864865\n",
            "F1 score 0.9765886287625419\n",
            "Testing time 0.0016520023345947266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall matplotlib\n",
        "!pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "84D3RDWWEBtg",
        "outputId": "99b3d6b5-ff5e-4334-ec77-2221a9172383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping matplotlib as it is not installed.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib==3.1.3\n",
            "  Downloading matplotlib-3.1.3-cp38-cp38-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.1.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.15.0)\n",
            "Installing collected packages: matplotlib\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autoviz 0.1.58 requires matplotlib>=3.3.3, but you have matplotlib 3.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.1.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "con_matrix=confusion_matrix(y_test, y_predSVM)\n",
        "fig, dx = plt.subplots(figsize=(10, 10))\n",
        "dx.matshow(con_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(con_matrix.shape[0]):\n",
        "    for j in range(con_matrix.shape[1]):\n",
        "        dx.text(x=j, y=i,s=con_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tkg9obLbXZ_3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "681fde7d-45c3-4df1-d16e-88f96fe2d8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF-qwhOAHDC2",
        "outputId": "b122692e-9fa2-43d2-a219-b83e7653c0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (5.6.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert) (0.7.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbconvert) (5.1.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (2.11.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (5.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert) (5.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (1.5.0)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.8/dist-packages (from nbconvert) (5.7.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert) (2.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.4->nbconvert) (2.0.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=4.4->nbconvert) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat>=4.4->nbconvert) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (5.10.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert) (22.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.4->nbconvert) (3.11.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert) (0.5.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert) (1.15.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbconvert) (2.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html ML_Assignment2.ipynb"
      ],
      "metadata": {
        "id": "KoBRAmhIHOjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8922b47-5e0f-460b-cc1e-833547844037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook ML_Assignment2.ipynb to html\n",
            "[NbConvertApp] ERROR | Notebook JSON is invalid: Additional properties are not allowed ('metadata' was unexpected)\n",
            "\n",
            "Failed validating 'additionalProperties' in stream:\n",
            "\n",
            "On instance['cells'][24]['outputs'][0]:\n",
            "{'metadata': {'tags': None},\n",
            " 'name': 'stdout',\n",
            " 'output_type': 'stream',\n",
            " 'text': 'Looking in indexes: https://pypi.org/simple, '\n",
            "         'https://us-python.p...'}\n",
            "/usr/local/lib/python3.8/dist-packages/nbconvert/filters/datatypefilter.py:39: UserWarning: Your element with mimetype(s) dict_keys(['application/vnd.colab-display-data+json']) is not able to be represented.\n",
            "  warn(\"Your element with mimetype(s) {mimetypes}\"\n",
            "[NbConvertApp] Writing 387393 bytes to ML_Assignment2.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bDTAXo3wR_5y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}